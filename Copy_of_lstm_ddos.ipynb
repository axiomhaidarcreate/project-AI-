{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/axiomhaidarcreate/project-AI-/blob/main/Copy_of_lstm_ddos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "dhoogla_cicddos2019_path = kagglehub.dataset_download('dhoogla/cicddos2019')\n",
        "azharzen_lstm_ddos_model_path = kagglehub.dataset_download('azharzen/lstm-ddos-model')\n",
        "\n",
        "print('Data source import complete.')"
      ],
      "metadata": {
        "id": "D254OOUusGGy",
        "outputId": "9d26aa9a-e6e6-4c43-e8ab-a19ffc4966da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data"
      ],
      "metadata": {
        "id": "cHR-DneDsGG5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aBz3AiSPvJrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from sklearn.utils import resample\n",
        "from sklearn import preprocessing\n",
        "\n",
        "import os\n",
        "dataset_path = []\n",
        "\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        if filename.endswith('.csv'):\n",
        "            dfp = os.path.join(dirname, filename)\n",
        "            dataset_path.append(dfp)"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2023-05-29T05:48:57.096881Z",
          "iopub.execute_input": "2023-05-29T05:48:57.097243Z",
          "iopub.status.idle": "2023-05-29T05:48:57.629298Z",
          "shell.execute_reply.started": "2023-05-29T05:48:57.097214Z",
          "shell.execute_reply": "2023-05-29T05:48:57.628419Z"
        },
        "trusted": true,
        "id": "C_GI0f0VsGG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset_path)"
      ],
      "metadata": {
        "id": "WQK8ZnwHt-YK",
        "outputId": "3d04679b-f874-466a-bc57-79eabd170020",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if len(dataset_path) > 1:\n",
        "    cols = list(pd.read_csv(dataset_path[1], nrows=1))\n",
        "else:\n",
        "    print(\"Error: dataset_path does not contain enough elements.\")"
      ],
      "metadata": {
        "id": "M3N4C8f0uGpS",
        "outputId": "d5528ca9-0670-4fe9-e636-a55ecf347069",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: dataset_path does not contain enough elements.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not dataset_path:\n",
        "    print(\"Error: dataset_path is empty.\")\n",
        "else:\n",
        "    print(\"Dataset paths:\", dataset_path)"
      ],
      "metadata": {
        "id": "CYWBsR4euX2v",
        "outputId": "82477964-f1c9-4bb0-ec58-12413ca5f9a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: dataset_path is empty.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not dataset_path:\n",
        "    print(\"Error: dataset_path is empty.\")\n",
        "else:\n",
        "    print(\"Dataset paths:\", dataset_path)"
      ],
      "metadata": {
        "id": "G0OIpkB5ua58",
        "outputId": "131b6bb2-038f-4eeb-9e1b-00b93ff20660",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: dataset_path is empty.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "for path in dataset_path:\n",
        "    if os.path.exists(path):\n",
        "        print(f\"File exists: {path}\")\n",
        "    else:\n",
        "        print(f\"File not found: {path}\")"
      ],
      "metadata": {
        "id": "_MhJ84NCueSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Dataset paths:\", dataset_path)"
      ],
      "metadata": {
        "id": "NWKgjjxdutF2",
        "outputId": "12dea8e0-53cb-4c63-a3d7-7964e436db2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset paths: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# إنشاء ملفات CSV وهمية\n",
        "df1 = pd.DataFrame({\"A\": [1, 2], \"B\": [3, 4]})\n",
        "df1.to_csv(\"path_to_first_dataset.csv\", index=False)\n",
        "\n",
        "df2 = pd.DataFrame({\"C\": [5, 6], \"D\": [7, 8]})\n",
        "df2.to_csv(\"path_to_second_dataset.csv\", index=False)\n",
        "\n",
        "dataset_path = [\"path_to_first_dataset.csv\", \"path_to_second_dataset.csv\"]\n",
        "print(\"Test files created.\")"
      ],
      "metadata": {
        "id": "j0_lCTQIu7fC",
        "outputId": "d42edafe-510b-44ff-df57-46cad8352a4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test files created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Dataset paths:\", dataset_path)"
      ],
      "metadata": {
        "id": "mwixfA3qvNe7",
        "outputId": "423774fe-e86f-4e13-8817-85d898e136b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset paths: ['path_to_first_dataset.csv', 'path_to_second_dataset.csv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from sklearn.utils import resample\n",
        "from sklearn import preprocessing\n",
        "\n",
        "import os\n",
        "dataset_path = []\n",
        "\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        if filename.endswith('.csv'):\n",
        "            dfp = os.path.join(dirname, filename)\n",
        "            dataset_path.append(dfp)"
      ],
      "metadata": {
        "id": "XXuUjiwXv7tE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mult = 5\n",
        "cols = list(pd.read_csv(dataset_path[1], nrows=1))\n",
        "\n",
        "def load_file(path):\n",
        "    # data = pd.read_csv(path, sep=',')\n",
        "    data = pd.read_csv(path,\n",
        "                   usecols =[i for i in cols if i != \" Source IP\"\n",
        "                             and i != ' Destination IP' and i != 'Flow ID'\n",
        "                             and i != 'SimillarHTTP' and i != 'Unnamed: 0'])\n",
        "\n",
        "    return data"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-29T05:49:29.578679Z",
          "iopub.execute_input": "2023-05-29T05:49:29.579035Z",
          "iopub.status.idle": "2023-05-29T05:49:29.608688Z",
          "shell.execute_reply.started": "2023-05-29T05:49:29.579007Z",
          "shell.execute_reply": "2023-05-29T05:49:29.607736Z"
        },
        "trusted": true,
        "id": "eDLojjTcsGHC",
        "outputId": "641708d8-ff7e-427c-fb0f-a3bc4e3db4e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "list index out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-4bb04a93df9f>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# mult = 5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# data = pd.read_csv(path, sep=',')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "samples = pd.concat([load_file(dfp) for dfp in dataset_path], ignore_index=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-29T05:49:46.523664Z",
          "iopub.execute_input": "2023-05-29T05:49:46.52402Z",
          "iopub.status.idle": "2023-05-29T05:50:03.055395Z",
          "shell.execute_reply.started": "2023-05-29T05:49:46.523992Z",
          "shell.execute_reply": "2023-05-29T05:50:03.054436Z"
        },
        "trusted": true,
        "id": "un4LjPlzsGHE",
        "outputId": "964d7e49-2be2-431e-f8d6-3df9bf7810cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Usecols do not match columns, columns expected but not found: ['C', 'D']",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-bbc9964d63b8>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mload_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdfp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset_path\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-21-bbc9964d63b8>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mload_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdfp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset_path\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-20-4bb04a93df9f>\u001b[0m in \u001b[0;36mload_file\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# data = pd.read_csv(path, sep=',')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     data = pd.read_csv(path,\n\u001b[0m\u001b[1;32m      7\u001b[0m                    usecols =[i for i in cols if i != \" Source IP\" \n\u001b[1;32m      8\u001b[0m                              \u001b[0;32mand\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m' Destination IP'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'Flow ID'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1897\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1898\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1899\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1900\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m    138\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             ):\n\u001b[0;32m--> 140\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_usecols_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0;31m# error: Cannot determine type of 'names'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_validate_usecols_names\u001b[0;34m(self, usecols, names)\u001b[0m\n\u001b[1;32m    977\u001b[0m         \u001b[0mmissing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0musecols\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    980\u001b[0m                 \u001b[0;34mf\"Usecols do not match columns, columns expected but not found: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m                 \u001b[0;34mf\"{missing}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Usecols do not match columns, columns expected but not found: ['C', 'D']"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Count the occurrences of each label\n",
        "label_counts = samples[' Label'].value_counts()\n",
        "\n",
        "# Create a bar plot to visualize the label counts\n",
        "plt.figure(figsize=(10, 6))\n",
        "label_counts.plot(kind='bar')\n",
        "plt.title('Comparison of Label Column')\n",
        "plt.xlabel('Label')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-29T05:50:34.931185Z",
          "iopub.execute_input": "2023-05-29T05:50:34.931538Z",
          "iopub.status.idle": "2023-05-29T05:50:35.557899Z",
          "shell.execute_reply.started": "2023-05-29T05:50:34.931509Z",
          "shell.execute_reply": "2023-05-29T05:50:35.557013Z"
        },
        "trusted": true,
        "id": "EyUPMMTosGHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-28T04:58:34.165723Z",
          "iopub.execute_input": "2023-05-28T04:58:34.166272Z",
          "iopub.status.idle": "2023-05-28T04:58:34.414386Z",
          "shell.execute_reply.started": "2023-05-28T04:58:34.166229Z",
          "shell.execute_reply": "2023-05-28T04:58:34.413436Z"
        },
        "trusted": true,
        "id": "KdwnIP0tsGHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# preprocess"
      ],
      "metadata": {
        "id": "vBY-toZtsGHN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# samples = samples_raw\n",
        "def string2numeric_hash(text):\n",
        "    import hashlib\n",
        "    return int(hashlib.md5(text).hexdigest()[:8], 16)\n",
        "\n",
        "# Flows Packet/s e Bytes/s - Replace infinity by 0\n",
        "samples = samples.replace('Infinity','0')\n",
        "samples = samples.replace(np.inf,0)\n",
        "#samples = samples.replace('nan','0')\n",
        "samples[' Flow Packets/s'] = pd.to_numeric(samples[' Flow Packets/s'])\n",
        "\n",
        "samples['Flow Bytes/s'] = samples['Flow Bytes/s'].fillna(0)\n",
        "samples['Flow Bytes/s'] = pd.to_numeric(samples['Flow Bytes/s'])\n",
        "\n",
        "\n",
        "#Label\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "# Create a label encoder object\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Fit the label encoder to the label column and transform the labels\n",
        "samples[' Label'] = label_encoder.fit_transform(samples[' Label'])\n",
        "\n",
        "# Get the mapping between original labels and encoded values\n",
        "label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
        "\n",
        "# Print the mapping\n",
        "for label, encoded_value in label_mapping.items():\n",
        "    print(f\"Label: {label} - Encoded Value: {encoded_value}\")\n",
        "\n",
        "#Timestamp - Drop day, then convert hour, minute and seconds to hashing\n",
        "colunaTime = pd.DataFrame(samples[' Timestamp'].str.split(' ',1).tolist(), columns = ['dia','horas'])\n",
        "colunaTime = pd.DataFrame(colunaTime['horas'].str.split('.',1).tolist(),columns = ['horas','milisec'])\n",
        "stringHoras = pd.DataFrame(colunaTime['horas'].str.encode('utf-8'))\n",
        "samples[' Timestamp'] = pd.DataFrame(stringHoras['horas'].apply(string2numeric_hash))#colunaTime['horas']\n",
        "del colunaTime,stringHoras\n",
        "\n",
        "\n",
        "print('Training data processed')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-29T05:50:44.278586Z",
          "iopub.execute_input": "2023-05-29T05:50:44.278977Z",
          "iopub.status.idle": "2023-05-29T05:50:53.913364Z",
          "shell.execute_reply.started": "2023-05-29T05:50:44.278934Z",
          "shell.execute_reply": "2023-05-29T05:50:53.912356Z"
        },
        "trusted": true,
        "id": "nX4rDnmqsGHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-29T07:30:49.866932Z",
          "iopub.execute_input": "2023-05-29T07:30:49.867365Z",
          "iopub.status.idle": "2023-05-29T07:30:50.346457Z",
          "shell.execute_reply.started": "2023-05-29T07:30:49.867334Z",
          "shell.execute_reply": "2023-05-29T07:30:50.345351Z"
        },
        "trusted": true,
        "id": "o3OOxs6fsGHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "from keras.models import Sequential\n",
        "\n",
        "from keras.layers import Dense,Embedding,Dropout,Flatten,MaxPooling1D,LSTM\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-29T05:50:58.280693Z",
          "iopub.execute_input": "2023-05-29T05:50:58.281041Z",
          "iopub.status.idle": "2023-05-29T05:51:05.681036Z",
          "shell.execute_reply.started": "2023-05-29T05:50:58.281012Z",
          "shell.execute_reply": "2023-05-29T05:51:05.680111Z"
        },
        "trusted": true,
        "id": "O7UFiOpbsGHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def LSTM_model(input_size):\n",
        "\n",
        "    # Initialize the constructor\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(LSTM(32,input_shape=(input_size,1), return_sequences=False))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(10, activation='relu'))\n",
        "#     model.add(Dense(1, activation='sigmoid'))\n",
        "    model.add(Dense(18, activation='softmax'))  # Update units and activation function\n",
        "\n",
        "    print(model.summary())\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-29T05:51:09.572818Z",
          "iopub.execute_input": "2023-05-29T05:51:09.573562Z",
          "iopub.status.idle": "2023-05-29T05:51:09.58108Z",
          "shell.execute_reply.started": "2023-05-29T05:51:09.573528Z",
          "shell.execute_reply": "2023-05-29T05:51:09.580085Z"
        },
        "trusted": true,
        "id": "HoCp0cj_sGHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test(samples):\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    import numpy as np\n",
        "\n",
        "    # Specify the data\n",
        "    X=samples.iloc[:,0:(samples.shape[1]-1)]\n",
        "\n",
        "    # Specify the target labels and flatten the array\n",
        "    #y= np.ravel(amostras.type)\n",
        "    y= samples.iloc[:,-1]\n",
        "\n",
        "    # Split the data up in train and test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test(samples)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-29T05:51:17.243491Z",
          "iopub.execute_input": "2023-05-29T05:51:17.243852Z",
          "iopub.status.idle": "2023-05-29T05:51:17.250588Z",
          "shell.execute_reply.started": "2023-05-29T05:51:17.243823Z",
          "shell.execute_reply": "2023-05-29T05:51:17.249511Z"
        },
        "trusted": true,
        "id": "ehqCkLJfsGHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_3d(df):\n",
        "\n",
        "    X = np.array(df)\n",
        "    return np.reshape(X, (X.shape[0], X.shape[1], 1))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-29T05:51:27.385219Z",
          "iopub.execute_input": "2023-05-29T05:51:27.385943Z",
          "iopub.status.idle": "2023-05-29T05:51:27.391019Z",
          "shell.execute_reply.started": "2023-05-29T05:51:27.385911Z",
          "shell.execute_reply": "2023-05-29T05:51:27.389842Z"
        },
        "trusted": true,
        "id": "3KseI6xWsGHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compile and train learning model\n",
        "\n",
        "def compile_train(model,X_train,y_train,deep=True, epochs=10):\n",
        "\n",
        "    if(deep==True):\n",
        "        import matplotlib.pyplot as plt\n",
        "#         optimizer = tfa.optimizers.AdamW(learning_rate=1e-3, weight_decay=0.001)\n",
        "#         model_lstm2.compile(optimizer=optimizer)\n",
        "\n",
        "#         model.compile(loss='binary_crossentropy',\n",
        "#                       optimizer='adam',\n",
        "#                       metrics=['accuracy'])\n",
        "        model.compile(loss='categorical_crossentropy',\n",
        "                      optimizer='adam',\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "        history = model.fit(X_train, y_train,epochs=epochs, batch_size=512, verbose=1)\n",
        "        #model.fit(X_train, y_train,epochs=3)\n",
        "\n",
        "        # summarize history for accuracy\n",
        "        plt.plot(history.history['accuracy'])\n",
        "        plt.title('model accuracy')\n",
        "        plt.ylabel('accuracy')\n",
        "        plt.xlabel('epoch')\n",
        "        plt.legend(['train'], loc='upper left')\n",
        "        plt.show()\n",
        "        # summarize history for loss\n",
        "        plt.plot(history.history['loss'])\n",
        "        plt.title('model loss')\n",
        "        plt.ylabel('loss')\n",
        "        plt.xlabel('epoch')\n",
        "        plt.legend(['train'], loc='upper left')\n",
        "        plt.show()\n",
        "\n",
        "        print(model.metrics_names)\n",
        "\n",
        "    else:\n",
        "        model.fit(X_train, y_train) #SVM, LR, GD\n",
        "\n",
        "    print('Model Compiled and Trained')\n",
        "    return model"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-29T05:51:32.777226Z",
          "iopub.execute_input": "2023-05-29T05:51:32.778054Z",
          "iopub.status.idle": "2023-05-29T05:51:32.787763Z",
          "shell.execute_reply.started": "2023-05-29T05:51:32.778013Z",
          "shell.execute_reply": "2023-05-29T05:51:32.786734Z"
        },
        "trusted": true,
        "id": "Rbuqp3Q8sGHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model and weights\n",
        "\n",
        "def save_model(model,name):\n",
        "    from keras.models import model_from_json\n",
        "\n",
        "    arq_json = 'Models/' + name + '.json'\n",
        "    model_json = model.to_json()\n",
        "    with open(arq_json,\"w\") as json_file:\n",
        "        json_file.write(model_json)\n",
        "\n",
        "    arq_h5 = 'Models/' + name + '.h5'\n",
        "    model.save_weights(arq_h5)\n",
        "    print('Model Saved')\n",
        "\n",
        "def load_model(name):\n",
        "    from keras.models import model_from_json\n",
        "\n",
        "    arq_json = 'Models/' + name + '.json'\n",
        "    json_file = open(arq_json,'r')\n",
        "    loaded_model_json = json_file.read()\n",
        "    json_file.close()\n",
        "    loaded_model = model_from_json(loaded_model_json)\n",
        "\n",
        "    arq_h5 = 'Models/' + name + '.h5'\n",
        "    loaded_model.load_weights(arq_h5)\n",
        "\n",
        "    print('Model loaded')\n",
        "\n",
        "    return loaded_model\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-29T05:51:37.877188Z",
          "iopub.execute_input": "2023-05-29T05:51:37.877846Z",
          "iopub.status.idle": "2023-05-29T05:51:37.885532Z",
          "shell.execute_reply.started": "2023-05-29T05:51:37.877813Z",
          "shell.execute_reply": "2023-05-29T05:51:37.884487Z"
        },
        "trusted": true,
        "id": "sAA7qacnsGHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resample"
      ],
      "metadata": {
        "id": "ETf2x0R_sGHi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# UPSAMPLE\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test(samples)\n",
        "\n",
        "\n",
        "#junta novamente pra aumentar o numero de normais\n",
        "X = pd.concat([X_train, y_train], axis=1)\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "X_train, y_train = SMOTE(random_state=42).fit_resample(X, X[' Label'])\n",
        "X_train = pd.DataFrame(X_train, columns=X_train.columns)\n",
        "\n",
        "X_train=X_train.drop(' Label', axis=1)\n",
        "input_size = (X_train.shape[1], 1)\n",
        "\n",
        "del X"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-29T05:51:52.951574Z",
          "iopub.execute_input": "2023-05-29T05:51:52.951922Z",
          "iopub.status.idle": "2023-05-29T05:56:10.80555Z",
          "shell.execute_reply.started": "2023-05-29T05:51:52.951894Z",
          "shell.execute_reply": "2023-05-29T05:56:10.80453Z"
        },
        "trusted": true,
        "id": "eoNj0z4bsGHj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Count the occurrences of each label\n",
        "label_counts = y_train.value_counts()\n",
        "\n",
        "# Create a bar plot to visualize the label counts\n",
        "plt.figure(figsize=(10, 6))\n",
        "label_counts.plot(kind='bar')\n",
        "plt.title('Comparison of Label Column')\n",
        "plt.xlabel('Label')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-29T05:56:10.80741Z",
          "iopub.execute_input": "2023-05-29T05:56:10.807869Z",
          "iopub.status.idle": "2023-05-29T05:56:11.169233Z",
          "shell.execute_reply.started": "2023-05-29T05:56:10.807834Z",
          "shell.execute_reply": "2023-05-29T05:56:11.168189Z"
        },
        "trusted": true,
        "id": "vtCX7E41sGHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "# labels = to_categorical(samples[' Label'])\n",
        "y_train= to_categorical(y_train)\n",
        "y_test= to_categorical(y_test)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-29T05:56:58.653621Z",
          "iopub.execute_input": "2023-05-29T05:56:58.653966Z",
          "iopub.status.idle": "2023-05-29T05:56:58.896671Z",
          "shell.execute_reply.started": "2023-05-29T05:56:58.653939Z",
          "shell.execute_reply": "2023-05-29T05:56:58.895724Z"
        },
        "trusted": true,
        "id": "JbokQn3fsGHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "Jo4guLbdsGHo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_lstm2 = LSTM_model(82)\n",
        "model_lstm2 = compile_train(model_lstm2,format_3d(X_train.astype(np.float32)),y_train.astype(np.float32), epochs=50)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-29T06:04:40.224572Z",
          "iopub.execute_input": "2023-05-29T06:04:40.22493Z",
          "iopub.status.idle": "2023-05-29T06:59:14.478525Z",
          "shell.execute_reply.started": "2023-05-29T06:04:40.224902Z",
          "shell.execute_reply": "2023-05-29T06:59:14.477582Z"
        },
        "trusted": true,
        "id": "TWVFbPChsGHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## save model"
      ],
      "metadata": {
        "id": "8TU5gNGYsGHq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir Models"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-29T06:59:14.480598Z",
          "iopub.execute_input": "2023-05-29T06:59:14.481237Z",
          "iopub.status.idle": "2023-05-29T06:59:15.56537Z",
          "shell.execute_reply.started": "2023-05-29T06:59:14.481193Z",
          "shell.execute_reply": "2023-05-29T06:59:15.564213Z"
        },
        "trusted": true,
        "id": "f-HkKgG9sGHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!touch 'Models/lstm_50e.json'\n",
        "save_model(model_lstm2,\"lstm_50e\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-29T06:59:31.791918Z",
          "iopub.execute_input": "2023-05-29T06:59:31.792315Z",
          "iopub.status.idle": "2023-05-29T06:59:32.864458Z",
          "shell.execute_reply.started": "2023-05-29T06:59:31.792263Z",
          "shell.execute_reply": "2023-05-29T06:59:32.863252Z"
        },
        "trusted": true,
        "id": "hZv9YWZNsGHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del model_lstm2"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-29T07:01:35.518878Z",
          "iopub.execute_input": "2023-05-29T07:01:35.519258Z",
          "iopub.status.idle": "2023-05-29T07:01:35.524028Z",
          "shell.execute_reply.started": "2023-05-29T07:01:35.519233Z",
          "shell.execute_reply": "2023-05-29T07:01:35.523009Z"
        },
        "trusted": true,
        "id": "CGOu1F_-sGHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load model"
      ],
      "metadata": {
        "id": "b1TKWQQ7sGHv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /kaggle/input/lstm-ddos-model/* /kaggle/working/Models/"
      ],
      "metadata": {
        "id": "du7NVUrfsGHw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lah Models"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-29T06:59:44.487525Z",
          "iopub.execute_input": "2023-05-29T06:59:44.487906Z",
          "iopub.status.idle": "2023-05-29T06:59:45.543Z",
          "shell.execute_reply.started": "2023-05-29T06:59:44.487875Z",
          "shell.execute_reply": "2023-05-29T06:59:45.541766Z"
        },
        "trusted": true,
        "id": "E7ytX1wcsGHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_lstm = load_model('lstm_50e')\n",
        "# model_lstm.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model_lstm.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-29T06:59:57.046021Z",
          "iopub.execute_input": "2023-05-29T06:59:57.046426Z",
          "iopub.status.idle": "2023-05-29T06:59:57.359075Z",
          "shell.execute_reply.started": "2023-05-29T06:59:57.046393Z",
          "shell.execute_reply": "2023-05-29T06:59:57.358135Z"
        },
        "trusted": true,
        "id": "quXGXTQ1sGHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction"
      ],
      "metadata": {
        "id": "ye_UiTXDsGH1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model_lstm.predict(format_3d(X_test))\n",
        "\n",
        "y_pred = y_pred.round()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-29T07:02:23.637672Z",
          "iopub.execute_input": "2023-05-29T07:02:23.638255Z",
          "iopub.status.idle": "2023-05-29T07:03:05.294907Z",
          "shell.execute_reply.started": "2023-05-29T07:02:23.63822Z",
          "shell.execute_reply": "2023-05-29T07:03:05.293919Z"
        },
        "trusted": true,
        "id": "2QEI8fo1sGH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_label = np.argmax(y_pred, axis=1)\n",
        "y_test_label = np.argmax(y_test, axis=1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-29T07:03:21.198962Z",
          "iopub.execute_input": "2023-05-29T07:03:21.199366Z",
          "iopub.status.idle": "2023-05-29T07:03:21.23062Z",
          "shell.execute_reply.started": "2023-05-29T07:03:21.199335Z",
          "shell.execute_reply": "2023-05-29T07:03:21.229718Z"
        },
        "trusted": true,
        "id": "DsltMUYGsGH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## evaluation"
      ],
      "metadata": {
        "id": "x_FtTeFDsGH7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# score = model_lstm2.evaluate(X_test, y_test,verbose=1)\n",
        "\n",
        "# print(score)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_test_label, y_pred_label)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-29T07:03:25.71249Z",
          "iopub.execute_input": "2023-05-29T07:03:25.713113Z",
          "iopub.status.idle": "2023-05-29T07:03:25.74021Z",
          "shell.execute_reply.started": "2023-05-29T07:03:25.71308Z",
          "shell.execute_reply": "2023-05-29T07:03:25.739173Z"
        },
        "trusted": true,
        "id": "A436m233sGIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "classification_report(y_test_label, y_pred_label)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-29T07:03:29.38277Z",
          "iopub.execute_input": "2023-05-29T07:03:29.383149Z",
          "iopub.status.idle": "2023-05-29T07:03:29.995625Z",
          "shell.execute_reply.started": "2023-05-29T07:03:29.38312Z",
          "shell.execute_reply": "2023-05-29T07:03:29.994419Z"
        },
        "trusted": true,
        "id": "UtArxUPFsGIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# '              precision    recall  f1-score   support\n",
        "\n",
        "#            0       0.47      0.99      0.64     37272\n",
        "#            1       0.70      0.34      0.45     10007\n",
        "#            2       0.00      0.00      0.00      4819\n",
        "#            3       0.43      0.45      0.44      5937\n",
        "#            4       0.99      0.97      0.98     42689\n",
        "#            5       0.59      0.31      0.40      5087\n",
        "#            6       0.41      0.76      0.53      4498\n",
        "#            7       0.53      0.27      0.36      6316\n",
        "#            8       0.00      0.00      0.00     13571\n",
        "#            9       0.60      0.14      0.22      8315\n",
        "#           10       0.64      0.11      0.19      5311\n",
        "#           11       0.74      0.53      0.62     14089\n",
        "#           12       1.00      0.99      0.99    118000\n",
        "#           13       0.99      0.99      0.99     75196\n",
        "#           14       0.67      0.66      0.66     11050\n",
        "#           15       0.84      0.87      0.86     10910\n",
        "#           16       0.07      0.84      0.12        25\n",
        "#           17       0.11      0.96      0.20        23\n",
        "\n",
        "#     accuracy                           0.83    373115\n",
        "#    macro avg       0.54      0.57      0.48    373115\n",
        "# weighted avg       0.82      0.83      0.80    373115\n",
        "# '\n"
      ],
      "metadata": {
        "id": "1YoBlECasGIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !apt -qqqq install aria2"
      ],
      "metadata": {
        "trusted": true,
        "id": "I7Bft9p9sGIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !mkdir dataset\n",
        "# !aria2c --console-log-level=error --summary-interval=10 -c -x 16 -k 1M -s 16 -d /kaggle/working/dataset -o PCAP-01-12_0750-0818.zip  http://205.174.165.80/CICDataset/CICDDoS2019/Dataset/PCAPs/01-12/PCAP-01-12_0750-0818.zip"
      ],
      "metadata": {
        "trusted": true,
        "id": "wwU3m-ahsGIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip -d /kaggle ./dataset/PCAP-01-12_0750-0818.zip"
      ],
      "metadata": {
        "trusted": true,
        "id": "QmFipM87sGIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !ls -lah /kaggle"
      ],
      "metadata": {
        "trusted": true,
        "id": "UzgnXNIwsGIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def parse_pcap(path):\n",
        "#     #TODO dunno how to do"
      ],
      "metadata": {
        "id": "jZENb4ntsGIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Contoh"
      ],
      "metadata": {
        "id": "2grh0WsbsGIp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# anngap file pcap sudah diextract menjadi csv\n",
        "def detect_anomaly(csv_path, model):\n",
        "    # read data\n",
        "    data = pd.read_csv(csv_path,\n",
        "               usecols =[i for i in cols if i != ' Destination IP' and i != 'Flow ID'\n",
        "                         and i != 'SimillarHTTP' and i != 'Unnamed: 0'])\n",
        "    source_ip = data[' Source IP']\n",
        "    data = data.drop(\" Source IP\", axis=1)\n",
        "\n",
        "    # only for data from dataset\n",
        "    data = data.drop(' Label', axis=1)\n",
        "\n",
        "    # preprocess\n",
        "    def string2numeric_hash(text):\n",
        "        import hashlib\n",
        "        return int(hashlib.md5(text).hexdigest()[:8], 16)\n",
        "\n",
        "    # Flows Packet/s e Bytes/s - Replace infinity by 0\n",
        "    data = data.replace('Infinity','0')\n",
        "    data = data.replace(np.inf,0)\n",
        "    #data = data.replace('nan','0')\n",
        "    data[' Flow Packets/s'] = pd.to_numeric(data[' Flow Packets/s'])\n",
        "\n",
        "    data['Flow Bytes/s'] = data['Flow Bytes/s'].fillna(0)\n",
        "    data['Flow Bytes/s'] = pd.to_numeric(data['Flow Bytes/s'])\n",
        "\n",
        "    #Timestamp - Drop day, then convert hour, minute and seconds to hashing\n",
        "    colunaTime = pd.DataFrame(data[' Timestamp'].str.split(' ',1).tolist(), columns = ['dia','horas'])\n",
        "    colunaTime = pd.DataFrame(colunaTime['horas'].str.split('.',1).tolist(),columns = ['horas','milisec'])\n",
        "    stringHoras = pd.DataFrame(colunaTime['horas'].str.encode('utf-8'))\n",
        "    data[' Timestamp'] = pd.DataFrame(stringHoras['horas'].apply(string2numeric_hash))#colunaTime['horas']\n",
        "    del colunaTime,stringHoras\n",
        "\n",
        "    predictions = model.predict(data)\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "\n",
        "    # Create a DataFrame of anomalies\n",
        "#     anomaly_df = pd.DataFrame()\n",
        "#     for i in range(len(predictions)):\n",
        "#         if predictions[i] != \"0\":\n",
        "#             anomaly_df = anomaly_df.append({' Source IP': source_ip[i], \"Label\": predictions[i]}, ignore_index=True)\n",
        "\n",
        "    anomaly_df = np.array([])\n",
        "    for i in range(len(predictions)):\n",
        "        if predictions[i] != 0:\n",
        "            anomaly_df = np.append(anomaly_df, [source_ip[i], predictions[i]])\n",
        "\n",
        "    # Print the IP address of the unique anomalies\n",
        "#     print(anomaly_df[\"IP\"].unique())\n",
        "    anomaly_df = anomaly_df.reshape(-1, 2)\n",
        "    label_map = {\n",
        "        '0': \"BENIGN\",\n",
        "        '1': \"DrDoS_DNS\",\n",
        "        '2': \"DrDoS_LDAP\",\n",
        "        '3': \"DrDoS_MSSQL\",\n",
        "        '4': \"DrDoS_NTP\",\n",
        "        '5': \"DrDoS_NetBIOS\",\n",
        "        '6': \"DrDoS_SNMP\",\n",
        "        '7': \"DrDoS_UDP\",\n",
        "        '8': \"LDAP\",\n",
        "        '9': \"MSSQL\",\n",
        "        '10': \"NetBIOS\",\n",
        "        '11': \"Portmap\",\n",
        "        '12': \"Syn\",\n",
        "        '13': \"TFTP\",\n",
        "        '14': \"UDP\",\n",
        "        '15': \"UDP-lag\",\n",
        "        '16': \"UDPLag\",\n",
        "        '17': \"WebDDoS\",\n",
        "    }\n",
        "    unique_values = np.unique(anomaly_df, axis=0)\n",
        "\n",
        "    # Print the results in a fancy format.\n",
        "    print('Source IP | anomaly')\n",
        "    print('===================')\n",
        "    for row in unique_values:\n",
        "        print(f\"{row[0]} | {label_map[row[1]]}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-29T07:04:16.420267Z",
          "iopub.execute_input": "2023-05-29T07:04:16.420647Z",
          "iopub.status.idle": "2023-05-29T07:04:16.435634Z",
          "shell.execute_reply.started": "2023-05-29T07:04:16.420618Z",
          "shell.execute_reply": "2023-05-29T07:04:16.434682Z"
        },
        "trusted": true,
        "id": "vJdhMQnqsGIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detect_anomaly('/kaggle/input/cicddos2019/DNS-testing.csv', model_lstm)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-29T07:29:27.172202Z",
          "iopub.execute_input": "2023-05-29T07:29:27.172925Z",
          "iopub.status.idle": "2023-05-29T07:29:48.07286Z",
          "shell.execute_reply.started": "2023-05-29T07:29:27.17289Z",
          "shell.execute_reply": "2023-05-29T07:29:48.071944Z"
        },
        "trusted": true,
        "id": "XfKkFLJ1sGIt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}